{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat\n",
    "* `00_dataset`폴더 내에 있는 원본파일을 동일 대상지(target)에서 촬영한 데이터끼리 합쳐서 `00_dataset_concated`에 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:28.595812Z",
     "iopub.status.busy": "2022-05-24T09:18:28.595812Z",
     "iopub.status.idle": "2022-05-24T09:18:28.608777Z",
     "shell.execute_reply": "2022-05-24T09:18:28.607809Z",
     "shell.execute_reply.started": "2022-05-24T09:18:28.595812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "* 촬영 대상지 번호, 촬영 순서, 영상 번호에 맞추어 파일들을 대상지별로 병합하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:28.609805Z",
     "iopub.status.busy": "2022-05-24T09:18:28.609805Z",
     "iopub.status.idle": "2022-05-24T09:18:28.623769Z",
     "shell.execute_reply": "2022-05-24T09:18:28.622774Z",
     "shell.execute_reply.started": "2022-05-24T09:18:28.609805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_dir = 'D:/OneDrive - 연세대학교 (Yonsei University)/Projects/Yonsei_TELab/003_도로상충_210517-/2차년도_2022/21_드론궤적분석자료_영업소_서울TG_부산방향/다차로하이패스/00_dataset' # 각 .csv 파일이 있는 폴더경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:28.624734Z",
     "iopub.status.busy": "2022-05-24T09:18:28.624734Z",
     "iopub.status.idle": "2022-05-24T09:18:28.639696Z",
     "shell.execute_reply": "2022-05-24T09:18:28.638728Z",
     "shell.execute_reply.started": "2022-05-24T09:18:28.624734Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02_1_1.csv', '02_1_2.csv', '02_1_3.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = os.listdir(file_dir)\n",
    "file_list[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:28.640692Z",
     "iopub.status.busy": "2022-05-24T09:18:28.640692Z",
     "iopub.status.idle": "2022-05-24T09:18:28.656650Z",
     "shell.execute_reply": "2022-05-24T09:18:28.654694Z",
     "shell.execute_reply.started": "2022-05-24T09:18:28.640692Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02'] \n",
      " ['1', '2', '3', '4', '5', '6'] \n",
      " ['1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "# 파일명으로부터 대상지 번호, 촬영 순서, 영상번호를 추출\n",
    "tgs = [] # 촬영 대상지 번호\n",
    "spots = [] # 촬영 지점\n",
    "videos = [] # 각 지점에서의 영상 번호\n",
    "\n",
    "for file in file_list: # 전체 파일 리스트를 돌며\n",
    "    tg = file[0:2] # 파일명으로부터 촬영 대상지 번호(2자리) 추출\n",
    "    spot = file[3] # 파일명으로부터 촬영지점(1자리) 추출\n",
    "    video = file[5] # 각 촬영지점에서의 영상번호(1자리) 추출\n",
    "    \n",
    "    if tg not in tgs:\n",
    "        tgs.append(tg)\n",
    "        \n",
    "    if spot not in spots:\n",
    "        spots.append(spot)\n",
    "        \n",
    "    if video not in videos:\n",
    "        videos.append(video)\n",
    "    \n",
    "print(tgs, '\\n', spots, '\\n', videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Numbering\n",
    "* 대상지별 데이터프레임을 불러와 넘버링하기\n",
    "* `video == 2`인 경우\n",
    "    * 차량번호(`Vehicle ID`)에 +10000\n",
    "    * 프레임 번호(`Frame ID`)에 +100000\n",
    "* `video == 3`인 경우\n",
    "    * 차량번호(`Vehicle ID`)에 +20000\n",
    "    * 프레임 번호(`Frame ID`)에 +200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:28.659643Z",
     "iopub.status.busy": "2022-05-24T09:18:28.657647Z",
     "iopub.status.idle": "2022-05-24T09:18:29.396051Z",
     "shell.execute_reply": "2022-05-24T09:18:29.395058Z",
     "shell.execute_reply.started": "2022-05-24T09:18:28.659643Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_list = [] # 데이터프레임 리스트\n",
    "num_list = [] # 데이터프레임 파일명, 즉 넘버링 리스트\n",
    "\n",
    "for tg in tgs:\n",
    "    for sp in spots:\n",
    "        for vd in videos:\n",
    "            num = tg + '_' + sp + '_' + vd # 파일명 넘버링\n",
    "            file_name = num + '.csv'\n",
    "            file_path = os.path.join(file_dir, file_name)\n",
    "            \n",
    "            if os.path.isfile(file_path): # 해당 file_path에 파일이 존재할 경우\n",
    "                globals()[f'target{num}'] = pd.read_csv(file_path, encoding = 'cp949') # .csv 파일을 불러와 인스턴스 만들기\n",
    "                df_list.append(globals()[f'target{num}']) \n",
    "                num_list.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:29.397046Z",
     "iopub.status.busy": "2022-05-24T09:18:29.397046Z",
     "iopub.status.idle": "2022-05-24T09:18:29.458850Z",
     "shell.execute_reply": "2022-05-24T09:18:29.456864Z",
     "shell.execute_reply.started": "2022-05-24T09:18:29.397046Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_vid = int(videos[-1])\n",
    "\n",
    "for df, num in zip(df_list, num_list): # 존재하는 데이터프레임 및 번호별로\n",
    "    if int(num[-1]) > 1: # spot이 1을 초과할 경우\n",
    "        \n",
    "        for i in range(2, max_vid+1):\n",
    "            if int(num[-1]) == i:\n",
    "                df['Vehicle ID'] = df['Vehicle ID'] + (i-1) * 10000\n",
    "                df['Frame ID'] = df['Frame ID'] + (i-1) * 100000\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat and Save\n",
    "* 대상지(`tg`)와 촬영지(`spot`)가 같은 파일들을 병합\n",
    "* 병합된 파일을 `00_dataset_concated` 폴더에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:29.459848Z",
     "iopub.status.busy": "2022-05-24T09:18:29.459848Z",
     "iopub.status.idle": "2022-05-24T09:18:29.474809Z",
     "shell.execute_reply": "2022-05-24T09:18:29.472849Z",
     "shell.execute_reply.started": "2022-05-24T09:18:29.459848Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_dir = 'D:/OneDrive - 연세대학교 (Yonsei University)/Projects/Yonsei_TELab/003_도로상충_210517-/2차년도_2022/17_드론궤적분석자료_2점분합류_금호JC_부산방향'\n",
    "folder_name = '00_dataset_concated' \n",
    "\n",
    "concat_dir = os.path.join(folder_dir, folder_name)\n",
    "\n",
    "os.makedirs(concat_dir, exist_ok = True) # 해당 경로가 없을 시 폴더 생성, 존재할 경우 건너뛰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:29.475806Z",
     "iopub.status.busy": "2022-05-24T09:18:29.475806Z",
     "iopub.status.idle": "2022-05-24T09:18:29.490765Z",
     "shell.execute_reply": "2022-05-24T09:18:29.488818Z",
     "shell.execute_reply.started": "2022-05-24T09:18:29.475806Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02_1', '02_2', '02_3', '02_4', '02_5', '02_6']\n"
     ]
    }
   ],
   "source": [
    "tg_spots = [] # num의 대상지 번호+촬영지점 번호 리스트\n",
    "\n",
    "for num in num_list:\n",
    "    tg_spot = num[0:4] # num의 대상지 번호+촬영지점 번호\n",
    "    \n",
    "    if tg_spot not in tg_spots:\n",
    "        tg_spots.append(tg_spot)\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(tg_spots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:29.492791Z",
     "iopub.status.busy": "2022-05-24T09:18:29.492791Z",
     "iopub.status.idle": "2022-05-24T09:18:32.237696Z",
     "shell.execute_reply": "2022-05-24T09:18:32.236696Z",
     "shell.execute_reply.started": "2022-05-24T09:18:29.492791Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# 각 빈 데이터프레임에 tg_spot이 일치하는 데이터프레임을 concat\n",
    "for tg_spot in tqdm(tg_spots):\n",
    "\n",
    "    globals()[f'target{tg_spot}'] = pd.DataFrame() # target01_1 등 각 tg_spot에 대한 빈 데이터프레임 생성\n",
    "    \n",
    "    for df, num in zip(df_list, num_list):\n",
    "        df_tg_spot = num[0:4] \n",
    "        \n",
    "        if df_tg_spot == tg_spot: # 만약 데이터프레임의 tg_spot이 일치할 경우\n",
    "            globals()[f'target{tg_spot}'] = pd.concat([globals()[f'target{tg_spot}'], df]) #데이터프레임 concat\n",
    "        \n",
    "        else:\n",
    "            pass # 그렇지 않을 경우, 패스\n",
    "        \n",
    "    concat_name = tg_spot + '.csv'# 새로 병합된 데이터프레임을 저장할 파일명\n",
    "    concat_path = os.path.join(concat_dir, concat_name)\n",
    "    \n",
    "    globals()[f'target{tg_spot}'].to_csv(concat_path, encoding = 'cp949') # 병합된 데이터프레임을 csv 파일로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Strange Value\n",
    "**촬영지점별로 병합된 파일(`00_dataset_concated`)에서 비정상적인 속도, 가속도 값을 가진 이상값 제거**\n",
    "* 속도 170 이상 / 15이하 제거\n",
    "* 가속도 -40이하, 40 이상 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:32.239685Z",
     "iopub.status.busy": "2022-05-24T09:18:32.238687Z",
     "iopub.status.idle": "2022-05-24T09:18:32.252650Z",
     "shell.execute_reply": "2022-05-24T09:18:32.251656Z",
     "shell.execute_reply.started": "2022-05-24T09:18:32.239685Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_name = '00_dataset_filtered_full'\n",
    "\n",
    "save_dir = os.path.join(folder_dir, folder_name)\n",
    "\n",
    "os.makedirs(save_dir, exist_ok = True) # 해당 경로가 없을 시 폴더 생성, 존재할 경우 건너뛰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:32.255643Z",
     "iopub.status.busy": "2022-05-24T09:18:32.254645Z",
     "iopub.status.idle": "2022-05-24T09:18:33.022085Z",
     "shell.execute_reply": "2022-05-24T09:18:33.022085Z",
     "shell.execute_reply.started": "2022-05-24T09:18:32.255643Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concate 된 파일을 기준으로 데이터프레임 리스트와 넘버링 리스트를 다시 재정의하기\n",
    "\n",
    "df_list = [] # 데이터프레임 리스트 초기화\n",
    "num_list = [] # 데이터프레임 파일명, 즉 넘버링 리스트 초기화\n",
    "\n",
    "for tg in tgs:\n",
    "    for sp in spots:\n",
    "        num = tg + '_' + sp # 파일명 넘버링\n",
    "        file_name = num + '.csv'\n",
    "        file_path = os.path.join(concat_dir, file_name)\n",
    "            \n",
    "        if os.path.isfile(file_path): # 해당 file_path에 파일이 존재할 경우\n",
    "            globals()[f'target{num}'] = pd.read_csv(file_path, encoding = 'cp949') # .csv 파일을 불러와 인스턴스 만들기\n",
    "            df_list.append(globals()[f'target{num}']) \n",
    "            num_list.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:18:33.022085Z",
     "iopub.status.busy": "2022-05-24T09:18:33.022085Z",
     "iopub.status.idle": "2022-05-24T09:18:35.635376Z",
     "shell.execute_reply": "2022-05-24T09:18:35.635376Z",
     "shell.execute_reply.started": "2022-05-24T09:18:33.022085Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df, num in zip(df_list, num_list):\n",
    "    \n",
    "    filtered_df = df[(df['Vehicle Velocity(km/h)'] <= 170) & (df['Vehicle Velocity(km/h)'] >= 15) & (df['Vehicle Acceleration'] <= 40) & (df['Vehicle Acceleration'] >= -40)] # 이상값 필터링\n",
    "    \n",
    "    save_name = f'{num}.csv'\n",
    "    save_path = os.path.join(save_dir, save_name)\n",
    "    \n",
    "    filtered_df.to_csv(save_path, encoding = 'cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
